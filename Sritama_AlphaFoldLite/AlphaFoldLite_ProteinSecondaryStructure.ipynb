{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpzAJHtWMj6_",
        "outputId": "ddb75c23-8ddf-4c73-9384-99e743edde0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shape: (15079, 12)\n",
            "After cleaning, total proteins: 15079\n",
            "Subsampled proteins used: 400\n",
            "                                                 seq  \\\n",
            "0  AAPANAVTADDPTAIALKYNQDATKSERVAAARPGLPPEEQHCANC...   \n",
            "1     TTCCPSIVARSNFNVCRLPGTPEALCATYTGCIIIPGATCPGDYAN   \n",
            "2  MAKWVCKICGYIYDEDAGDPDNGISPGTKFEELPDDWVCPICGAPK...   \n",
            "3  NKASVVANQLIPINTALTLIMMKAEVVTPMGIPAEEIPKLVGMQVN...   \n",
            "4  ATGGYVQQATGQASFTMYSGCGSPACGKAASGFTAAINQLAFGSAP...   \n",
            "\n",
            "                                                sst3  \n",
            "0  CCCCCECCCCCHHHHHHCCECCHHHCCHHHHCCCCCCHHHCCHHHE...  \n",
            "1     CEECCCHHHHHHHHHHHCCCCCHHHHHHHHCCEECCCCCCCCCCCC  \n",
            "2  CCEEEECCCCCEEECCCCEHHHCECCCCCHHHCCCCCECCCCCCEH...  \n",
            "3  CCCEEEECCCECCCCECCHHHEEEECCCCCCCEHHHHHHHCCCEEC...  \n",
            "4  CHHHCCCCCEEEEEEEEECCCCCCCCCCCECCCEEEEEHHHHCCCC...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"protein.csv\")\n",
        "print(\"Original shape:\", df.shape)\n",
        "\n",
        "# Keep only needed columns\n",
        "df = df[[\"seq\", \"sst3\"]].dropna()\n",
        "\n",
        "# Ensure lengths match\n",
        "df = df[df[\"seq\"].str.len() == df[\"sst3\"].str.len()]\n",
        "\n",
        "# Have used only  the first N proteins to save RAM\n",
        "N_PROTEINS = 400   # you can adjust: 200, 300, 400 depending on speed\n",
        "df_small = df.iloc[:N_PROTEINS].reset_index(drop=True)\n",
        "\n",
        "print(\"After cleaning, total proteins:\", df.shape[0])\n",
        "print(\"Subsampled proteins used:\", df_small.shape[0])\n",
        "print(df_small.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVG6pE7IMndB",
        "outputId": "d14397f4-979b-46c7-81b5-8bbca7a8ea1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (36936, 140)\n",
            "y shape: (36936,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "AA_LIST = \"ACDEFGHIKLMNPQRSTVWY\"\n",
        "WINDOW_SIZE = 7   # smaller than 11 to reduce feature size\n",
        "HALF = WINDOW_SIZE // 2\n",
        "\n",
        "def seq_to_onehot(seq):\n",
        "    aa_to_idx = {aa: i for i, aa in enumerate(AA_LIST)}\n",
        "    mat = np.zeros((len(seq), len(AA_LIST)), dtype=np.float32)\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa in aa_to_idx:\n",
        "            mat[i, aa_to_idx[aa]] = 1.0\n",
        "    return mat\n",
        "\n",
        "def create_windows_and_labels(seq, ss, window=WINDOW_SIZE, step=2):\n",
        "    \"\"\"\n",
        "    step: use every 'step' residue to lower number of samples\n",
        "    e.g., step=2 takes every second residue\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    onehot = seq_to_onehot(seq)\n",
        "    L = len(seq)\n",
        "    for i in range(HALF, L - HALF, step):\n",
        "        w = onehot[i - HALF : i + HALF + 1].flatten()\n",
        "        X.append(w)\n",
        "        y.append(ss[i])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_list, y_list = [], []\n",
        "\n",
        "for _, row in df_small.iterrows():\n",
        "    seq = row[\"seq\"]\n",
        "    ss  = row[\"sst3\"]\n",
        "    if len(seq) < WINDOW_SIZE:\n",
        "        continue\n",
        "    X_w, y_w = create_windows_and_labels(seq, ss, WINDOW_SIZE, step=2)  # step=2 reduces samples\n",
        "    X_list.append(X_w)\n",
        "    y_list.append(y_w)\n",
        "\n",
        "X = np.vstack(X_list)\n",
        "y = np.hstack(y_list)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lg-su-FMxMe",
        "outputId": "585a0010-d3b9-4920-c4a9-cddd0c6bc24d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 29548 Test size: 7388\n",
            "Classes: ['C' 'E' 'H']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_enc, test_size=0.2, random_state=42, stratify=y_enc\n",
        ")\n",
        "\n",
        "print(\"Train size:\", X_train.shape[0], \"Test size:\", X_test.shape[0])\n",
        "print(\"Classes:\", le.classes_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pCs916wM-sS",
        "outputId": "8846e447-802c-4663-a2f3-1df7904dc0a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression accuracy: 0.5916350839198701\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           C       0.63      0.68      0.65      3035\n",
            "           E       0.54      0.47      0.50      1952\n",
            "           H       0.58      0.58      0.58      2401\n",
            "\n",
            "    accuracy                           0.59      7388\n",
            "   macro avg       0.58      0.58      0.58      7388\n",
            "weighted avg       0.59      0.59      0.59      7388\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "lr = LogisticRegression(\n",
        "    max_iter=300,    # you can increase later if needed\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "print(\"Logistic Regression accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test, y_pred_lr, target_names=le.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTchZzfnNHHW",
        "outputId": "e7bf240b-32c6-40d9-d4c3-a9b3e3e7a6b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP accuracy: 0.6111261505143476\n",
            "\n",
            "MLP classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           C       0.62      0.71      0.66      3035\n",
            "           E       0.58      0.48      0.53      1952\n",
            "           H       0.62      0.60      0.61      2401\n",
            "\n",
            "    accuracy                           0.61      7388\n",
            "   macro avg       0.61      0.59      0.60      7388\n",
            "weighted avg       0.61      0.61      0.61      7388\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(64,),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=15,    # keep small to avoid long training\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "print(\"MLP accuracy:\", accuracy_score(y_test, y_pred_mlp))\n",
        "print(\"\\nMLP classification report:\")\n",
        "print(classification_report(y_test, y_pred_mlp, target_names=le.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFLSY9ADJxJz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
